{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some misc. code snippets while learning diffusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload\n",
    "# import libraries\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "import os\n",
    "import sys\n",
    "import torchvision.utils as vutils\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML\n",
    "import torch\n",
    "%matplotlib inline\n",
    "\n",
    "from celeba_dataset import CelebA\n",
    "from unet_diffusion import UNet_Diffusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload\n",
    "import os\n",
    "import torch\n",
    "import glob\n",
    "from torch import utils\n",
    "from torch import nn\n",
    "import pytorch_lightning as pl\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms.v2 import Resize, Compose, ToDtype, RandomHorizontalFlip, RandomVerticalFlip \n",
    "from torchvision.transforms.v2 import RandomResizedCrop, RandomRotation, GaussianBlur, RandomErasing\n",
    "\n",
    "\n",
    "#--------------------------------------------------------------------\n",
    "# Dataset, Dataloader\n",
    "#--------------------------------------------------------------------\n",
    "from pathlib import Path\n",
    "image_dir_train = Path('../data/img_align_celeba/img_align_celeba/train/')\n",
    "image_dir_valid = Path('../data/img_align_celeba/img_align_celeba/valid/')\n",
    "\n",
    "img_size = (64,64) \n",
    "batch_size = 8 \n",
    "\n",
    "\n",
    "train_transforms = Compose([ToDtype(torch.float32, scale=False),\n",
    "                            RandomHorizontalFlip(p=0.50),\n",
    "                            # RandomVerticalFlip(p=0.25),\n",
    "                            # transforms.RandomApply(nn.ModuleList([GaussianBlur(kernel_size=7)]), p=0.5),\n",
    "                            # transforms.RandomApply(nn.ModuleList([RandomRotation(10.0)]), p=0.5),\n",
    "                            # RandomResizedCrop(size=img_size, scale=(0.3, 1.0), antialias=True),\n",
    "                            # RandomErasing(p=0.5, scale=(0.02, 0.20)),\n",
    "                            Resize(img_size, antialias=True)\n",
    "                            ])\n",
    "\n",
    "valid_transforms = Compose([ToDtype(torch.float32, scale=False),\n",
    "                            Resize(img_size, antialias=True)\n",
    "                            ])\n",
    "\n",
    "train_dataset = CelebA(image_dir_train, transform=train_transforms)\n",
    "train_loader = utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle = True, num_workers=5, persistent_workers=True)\n",
    "\n",
    "valid_dataset = CelebA(image_dir_valid, transform=valid_transforms)\n",
    "valid_loader = utils.data.DataLoader(valid_dataset, batch_size=batch_size, shuffle = False, num_workers=5, persistent_workers=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import glob\n",
    "# image_dir_train = '../data/img_align_celeba/img_align_celeba/'\n",
    "# img_list = glob.glob(image_dir_train+'*.jpg')\n",
    "# print(len(img_list))\n",
    "\n",
    "# num_train = int(len(img_list)*0.9)\n",
    "# print('num_train:', num_train)\n",
    "# num_valid = len(img_list) - num_train\n",
    "# print('num valid:', num_valid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import random\n",
    "# # shuffle the list\n",
    "# random.shuffle(img_list)\n",
    "# train_file_names = img_list[0:num_train]\n",
    "# valid_file_names = img_list[num_train:]\n",
    "\n",
    "# print(len(train_file_names))\n",
    "# print(len(valid_file_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# print(train_file_names[0])\n",
    "# print(os.path.abspath(train_file_names[0]))\n",
    "# os.makedirs('../data/img_align_celeba/img_align_celeba/train/', exist_ok=True)\n",
    "# os.makedirs('../data/img_align_celeba/img_align_celeba/valid/', exist_ok=True)\n",
    "\n",
    "# # make 80/20 train/valid split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import shutil\n",
    "\n",
    "# for i, f in enumerate(valid_file_names):\n",
    "#     shutil.move(f, '../data/img_align_celeba/img_align_celeba/valid/')\n",
    "#     if i % 100 == 0:\n",
    "#         print(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%ls -l '../data/img_align_celeba/img_align_celeba/train/' | wc -l\n",
    "%ls -l '../data/img_align_celeba/img_align_celeba/valid/' | wc -l\n",
    "%ls -l '../data/img_align_celeba/img_align_celeba/' | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnNormalize(object):\n",
    "    def __init__(self) : #, mean, std):\n",
    "        pass\n",
    "    def __call__(self, img):\n",
    "        img = (img*127.5) + 127.5\n",
    "        return img\n",
    "    \n",
    "unorm  = UnNormalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imga, imgb = train_dataset.__getitem__(0)\n",
    "print(imga.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "images, _  = next(iter(train_loader))\n",
    "print(images.shape)\n",
    "print(torch.min(images[0]), ', ', torch.max(images[0]))\n",
    "\n",
    "\n",
    "cols = 4\n",
    "rows = 4\n",
    "print('num rows:', rows, ', num cols:', cols)\n",
    "plt.figure(figsize=(10, 10))\n",
    "idx = 0\n",
    "for img in (images):  \n",
    "    img = unorm(img).to(torch.uint8).permute(1, 2, 0)\n",
    "    # target = unorm(target).to(torch.uint8).permute(1, 2, 0)\n",
    "\n",
    "    idx += 1\n",
    "    ax = plt.subplot(rows, cols, idx)\n",
    "    ax.axis('off')\n",
    "    plt.imshow(img)\n",
    "\n",
    "    # idx += 1\n",
    "    # ax = plt.subplot(rows, cols, idx)\n",
    "    # ax.axis('off')\n",
    "    # plt.imshow(target)\n",
    "\n",
    "    if idx == (cols*rows):\n",
    "        break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "avm-dvm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
