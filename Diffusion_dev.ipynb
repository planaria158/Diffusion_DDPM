{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some misc. code snippets while learning diffusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload\n",
    "# import libraries\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "import os\n",
    "import sys\n",
    "import torchvision.utils as vutils\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML\n",
    "import torch\n",
    "%matplotlib inline\n",
    "\n",
    "from celeba_dataset import CelebA\n",
    "from unet_diffusion import UNet_Diffusion, get_time_embedding\n",
    "from noise_scheduler import LinearNoiseScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = (64,64) \n",
    "batch_size = 8 \n",
    "num_timesteps = 1000\n",
    "beta_start = 0.0001\n",
    "beta_end = 0.02\n",
    "lns = LinearNoiseScheduler(num_timesteps, beta_start, beta_end)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------------------\n",
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create two random vectors and interpolate between them.\n",
    "# rand_a = torch.randn(3, 64, 64)\n",
    "# rand_b = torch.randn(3, 64, 64)\n",
    "# delta_ab = rand_a - rand_b\n",
    "# print(delta_ab.shape)\n",
    "# num_samples = 10\n",
    "\n",
    "# samples = []\n",
    "# samples.append(rand_a)\n",
    "# delt = 1.0/num_samples\n",
    "# for i in range(1, 9, 1):\n",
    "#     s = rand_a + (i * delt) * delta_ab\n",
    "#     samples.append(s)\n",
    "\n",
    "# samples.append(rand_b)\n",
    "# print('len(samples):', len(samples))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model\n",
    "time_emb_dim = 256 #128\n",
    "\n",
    "\n",
    "import torchvision\n",
    "import argparse\n",
    "import yaml\n",
    "import os\n",
    "from torchvision.utils import make_grid\n",
    "from unet_diffusion import UNet_Diffusion\n",
    "from diffusion_lightning import DDPM\n",
    "from tqdm import tqdm\n",
    "\n",
    "num_samples = 25\n",
    "num_grid_rows = 5\n",
    "im_channels = 3\n",
    "im_size = img_size[0]\n",
    "num_timesteps = 1000\n",
    "beta_start = 0.0001\n",
    "beta_end = 0.02\n",
    "task_name = 'default'\n",
    "ckpt_name = 'model_ckpt.pth'\n",
    "\n",
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "def sample(model, scheduler):\n",
    "    \"\"\"\n",
    "    Sample stepwise by going backward one timestep at a time.\n",
    "    We save the x0 predictions\n",
    "    \"\"\"\n",
    "\n",
    "    # # Create two random vectors and interpolate between them.\n",
    "    # rand_a = torch.randn(im_channels, im_size, im_size)\n",
    "    # rand_b = torch.randn(im_channels, im_size, im_size)\n",
    "    # delta_ab = rand_a - rand_b\n",
    "    # samples = []\n",
    "    # samples.append(rand_a)\n",
    "    # delt = 1.0/num_samples\n",
    "    # for i in range(1, (num_samples-1), 1):\n",
    "    #     s = rand_a + (i * delt) * delta_ab\n",
    "    #     samples.append(s)\n",
    "\n",
    "    # samples.append(rand_b)\n",
    "    # xt = torch.stack(samples).to(device)\n",
    "    # print('xt shape:', xt.shape)\n",
    "\n",
    "    xt = torch.randn((num_samples, im_channels, im_size, im_size)).to(device)\n",
    "\n",
    "    for i in tqdm(reversed(range(num_timesteps))):\n",
    "        # Get prediction of noise\n",
    "        noise_pred = model(xt, torch.as_tensor(i).unsqueeze(0).to(device))\n",
    "        \n",
    "        # Use scheduler to get x0 and xt-1\n",
    "        xt, x0_pred = scheduler.sample_prev_timestep(xt, noise_pred, torch.as_tensor(i).to(device))\n",
    "        \n",
    "        # Save x0 every 200th time.\n",
    "        if i % 200 == 0 or (i == num_timesteps-1):\n",
    "            ims = torch.clamp(xt, -1., 1.).detach().cpu()\n",
    "            ims = (ims + 1) / 2\n",
    "            grid = make_grid(ims, nrow=num_grid_rows)\n",
    "            img = torchvision.transforms.ToPILImage()(grid)\n",
    "            if not os.path.exists(os.path.join(task_name, 'samples')):\n",
    "                os.mkdir(os.path.join(task_name, 'samples'))\n",
    "            img.save(os.path.join(task_name, 'samples', 'x0_{}.png'.format(i)))\n",
    "            img.close()\n",
    "\n",
    "\n",
    "def infer():\n",
    "    map_location = {'cuda:0':'cuda:1'}\n",
    "    model = DDPM.load_from_checkpoint(checkpoint_path='/home/mark/dev/diffusion/lightning_logs/version_12/checkpoints/epoch=9-step=182340.ckpt',\n",
    "                                      map_location=map_location)\n",
    "    \n",
    "    model.ema_model = None # dump the extra EMA model (to reduce memory footprint)\n",
    "\n",
    "    total_params = sum(param.numel() for param in model.parameters())\n",
    "    print('Model has:', int(total_params//1e6), 'M parameters')\n",
    "\n",
    "    \n",
    "    # model = UNet_Diffusion(time_emb_dim).to(device)\n",
    "    # model.load_state_dict(torch.load(os.path.join(task_name, ckpt_name), map_location=device))\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    \n",
    "    # Create the noise scheduler\n",
    "    scheduler = LinearNoiseScheduler(num_timesteps=num_timesteps,\n",
    "                                     beta_start=beta_start,\n",
    "                                     beta_end=beta_end)\n",
    "    with torch.no_grad():\n",
    "        sample(model.model, scheduler)\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "\n",
    "#----------------------------------------------------\n",
    "# Run the inference\n",
    "#----------------------------------------------------\n",
    "infer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu, sigma = 0, 0.1 # mean and standard deviation\n",
    "s = np.random.normal(mu, sigma, 1000)\n",
    "\n",
    "\n",
    "# Verify the mean and the variance: \n",
    "abs(mu - np.mean(s))\n",
    "0.0  # may vary\n",
    "\n",
    "abs(sigma - np.std(s, ddof=1))\n",
    "0.1  # may vary\n",
    "\n",
    "\n",
    "# Display the histogram of the samples, along with the probability density function:\n",
    "count, bins, ignored = plt.hist(s, 30, density=True)\n",
    "plt.plot(bins, 1/(sigma * np.sqrt(2 * np.pi)) *\n",
    "               np.exp( - (bins - mu)**2 / (2 * sigma**2) ),\n",
    "         linewidth=2, color='r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload\n",
    "import os\n",
    "import torch\n",
    "from torch import utils\n",
    "from torch import nn\n",
    "import pytorch_lightning as pl\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms.v2 import Resize, Compose, ToDtype, RandomHorizontalFlip, RandomVerticalFlip \n",
    "from torchvision.transforms.v2 import RandomResizedCrop, RandomRotation, GaussianBlur, RandomErasing\n",
    "\n",
    "\n",
    "#--------------------------------------------------------------------\n",
    "# Dataset, Dataloader\n",
    "#--------------------------------------------------------------------\n",
    "from pathlib import Path\n",
    "image_dir_train = Path('../data/img_align_celeba/img_align_celeba/')\n",
    "\n",
    "img_size = (64,64) \n",
    "batch_size = 8 \n",
    "\n",
    "\n",
    "train_transforms = Compose([ToDtype(torch.float32, scale=False),\n",
    "                            RandomHorizontalFlip(p=0.50),\n",
    "                            # RandomVerticalFlip(p=0.25),\n",
    "                            # transforms.RandomApply(nn.ModuleList([GaussianBlur(kernel_size=7)]), p=0.5),\n",
    "                            # transforms.RandomApply(nn.ModuleList([RandomRotation(10.0)]), p=0.5),\n",
    "                            # RandomResizedCrop(size=img_size, scale=(0.3, 1.0), antialias=True),\n",
    "                            # RandomErasing(p=0.5, scale=(0.02, 0.20)),\n",
    "                            Resize(img_size, antialias=True)\n",
    "                            ])\n",
    "\n",
    "train_dataset = CelebA(image_dir_train, transform=train_transforms)\n",
    "train_loader = utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle = True, num_workers=5, persistent_workers=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnNormalize(object):\n",
    "    def __init__(self) : #, mean, std):\n",
    "        pass\n",
    "    def __call__(self, img):\n",
    "        img = (img*127.5) + 127.5\n",
    "        return img\n",
    "    \n",
    "unorm  = UnNormalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "images, _  = next(iter(train_loader))\n",
    "print(images.shape)\n",
    "print(torch.min(images[0]), ', ', torch.max(images[0]))\n",
    "\n",
    "\n",
    "cols = 4\n",
    "rows = 4\n",
    "print('num rows:', rows, ', num cols:', cols)\n",
    "plt.figure(figsize=(10, 10))\n",
    "idx = 0\n",
    "for img in (images):  \n",
    "    img = unorm(img).to(torch.uint8).permute(1, 2, 0)\n",
    "    # target = unorm(target).to(torch.uint8).permute(1, 2, 0)\n",
    "\n",
    "    idx += 1\n",
    "    ax = plt.subplot(rows, cols, idx)\n",
    "    ax.axis('off')\n",
    "    plt.imshow(img)\n",
    "\n",
    "    if idx == (cols*rows):\n",
    "        break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_0, _  = next(iter(train_loader))\n",
    "shape = images_0.shape\n",
    "print(shape)\n",
    "noise = torch.randn(shape[2], shape[3])\n",
    "print(noise.shape)\n",
    "print(images[0:5].shape)\n",
    "\n",
    "imgs_n = lns.add_noise(images[0:1], noise, 50)\n",
    "print(imgs_n.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "cols = 2\n",
    "rows = 1\n",
    "print('num rows:', rows, ', num cols:', cols)\n",
    "plt.figure(figsize=(5, 5))\n",
    "idx = 0\n",
    "\n",
    "img   = unorm(images[0]).to(torch.uint8).permute(1, 2, 0)\n",
    "img_n = unorm(imgs_n[0]).to(torch.uint8).permute(1, 2, 0)\n",
    "\n",
    "idx += 1\n",
    "ax = plt.subplot(rows, cols, idx)\n",
    "ax.axis('off')\n",
    "plt.imshow(img)\n",
    "\n",
    "idx += 1\n",
    "ax = plt.subplot(rows, cols, idx)\n",
    "ax.axis('off')\n",
    "plt.imshow(img_n)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_emb_dim = 128\n",
    "time_steps = torch.ones((512)) * 999\n",
    "print(time_steps.shape)\n",
    "\n",
    "blah = time_steps[:, None]\n",
    "print(blah.shape)\n",
    "\n",
    "poo = blah.repeat(1, 128//2)\n",
    "print(poo.shape)\n",
    "\n",
    "\n",
    "t_emb = get_time_embedding(time_steps, time_emb_dim)\n",
    "print(t_emb.shape)\n",
    "print(t_emb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------\n",
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------------------------------------\n",
    "#\n",
    "# DDPM Diffusion Model\n",
    "# as a pytorch lightning module.\n",
    "#\n",
    "#--------------------------------------------------------------------\n",
    "\n",
    "import torch\n",
    "from pytorch_lightning.core import LightningModule\n",
    "from torch import nn\n",
    "import pytorch_lightning as pl\n",
    "import copy\n",
    "\n",
    "from unet_diffusion import UNet_Diffusion\n",
    "from noise_scheduler import LinearNoiseScheduler\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Exponential moving average for more stable training\n",
    "# copied from https://github.com/dome272/Diffusion-Models-pytorch\n",
    "# -------------------------------------------------------------------\n",
    "class EMA:\n",
    "    def __init__(self, beta):\n",
    "        super().__init__()\n",
    "        self.beta = beta\n",
    "        self.step = 0\n",
    "\n",
    "    def update_model_average(self, ma_model, current_model):\n",
    "        for current_params, ma_params in zip(current_model.parameters(), ma_model.parameters()):\n",
    "            old_weight, up_weight = ma_params.data, current_params.data\n",
    "            ma_params.data = self.update_average(old_weight, up_weight)\n",
    "\n",
    "    def update_average(self, old, new):\n",
    "        if old is None:\n",
    "            return new\n",
    "        return old * self.beta + (1 - self.beta) * new\n",
    "\n",
    "    def step_ema(self, ema_model, model, step_start_ema=2000):\n",
    "        if self.step < step_start_ema:\n",
    "            self.reset_parameters(ema_model, model)\n",
    "            self.step += 1\n",
    "            return\n",
    "        self.update_model_average(ema_model, model)\n",
    "        self.step += 1\n",
    "\n",
    "    def reset_parameters(self, ema_model, model):\n",
    "        ema_model.load_state_dict(model.state_dict())\n",
    "\n",
    "\n",
    "\n",
    "class DDPM(LightningModule):\n",
    "    def __init__(self,\n",
    "                **kwargs):\n",
    "        super().__init__()\n",
    "        self.criterion = nn.MSELoss()\n",
    "        self.num_timesteps = 1000\n",
    "        self.beta_start = 0.0001\n",
    "        self.beta_end = 0.02\n",
    "        self.time_emb_dim = 256\n",
    "        self.num_epochs = 500\n",
    "        self.model = UNet_Diffusion(self.time_emb_dim)\n",
    "        self.scheduler = LinearNoiseScheduler(self.num_timesteps, self.beta_start, self.beta_end)\n",
    "        self.ema = EMA(0.995)\n",
    "        self.ema_model = copy.deepcopy(self.model).eval().requires_grad_(False)\n",
    "\n",
    "        # print('self.optimizers:', self.optimizers)\n",
    "        # print('self.lr_schedulers:', self.lr_schedulers)\n",
    "        print('self.current_epoch:', self.current_epoch)\n",
    "\n",
    "        self.save_hyperparameters()\n",
    "    \n",
    "    def forward(self, noisy_im, t):\n",
    "        return self.model(noisy_im, t)\n",
    "    \n",
    "    def common_forward(self, batch):\n",
    "        imgs = batch[0]\n",
    "        # Random noise\n",
    "        noise = torch.randn_like(imgs) \n",
    "        # Timestep\n",
    "        tstep = torch.randint(0, self.num_timesteps, (imgs.shape[0],)) \n",
    "        # Add noise to images according to timestep\n",
    "        noisy_imgs = self.scheduler.add_noise(imgs, noise, tstep).to(imgs)\n",
    "        # Model tries to learn the noise that was added to im to make noise_im\n",
    "        noise_pred = self.forward(noisy_imgs, tstep.to(imgs))\n",
    "        # Loss is our predicted noise relative to actual noise\n",
    "        loss = self.criterion(noise_pred, noise)\n",
    "        return loss\n",
    "    \n",
    "    # ---------------------------------------------------------------\n",
    "    # Training step:\n",
    "    # ---------------------------------------------------------------\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        loss = self.common_forward(batch)\n",
    "        self.log_dict({\"loss\": loss}, prog_bar=True, sync_dist=True)\n",
    "        return loss\n",
    "    \n",
    "    def on_train_batch_end(self, outputs, batch, batch_idx):\n",
    "        # After every batch, apply the EMA-based weights update\n",
    "        self.ema.step_ema(self.ema_model, self.model)\n",
    "        return\n",
    "\n",
    "    # ---------------------------------------------------------------\n",
    "    # Validation step:\n",
    "    # ---------------------------------------------------------------\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        val_loss = self.common_forward(batch)\n",
    "        self.log_dict({\"val_loss\": val_loss}, prog_bar=True, sync_dist=True)\n",
    "        return val_loss\n",
    "    \n",
    "    def on_load_checkpoint(self, checkpoint):\n",
    "        print(\"\\nRestarting from checkpoint\")\n",
    "        print(type(checkpoint))\n",
    "        print(checkpoint.keys())\n",
    "        print('epoch:', checkpoint['epoch'])\n",
    "        print('global_step:', checkpoint['global_step'])\n",
    "        print('lr_schedulers:', checkpoint['lr_schedulers'])\n",
    "        print('loops:', checkpoint['loops'])\n",
    "        print('hyper_parameters:', checkpoint['hyper_parameters'])\n",
    "        print('type(optimizer_states):', type(checkpoint['optimizer_states'][0]))\n",
    "        print('self.current_epoch;', self.current_epoch)\n",
    "        self.current_epoch = checkpoint['epoch']\n",
    "\n",
    "        self.ema_model = copy.deepcopy(self.model).eval().requires_grad_(False)\n",
    "        self.ema.step = checkpoint['global_step'] \n",
    "        print('on_load_checkpoint: calling self.ema.step:', self.ema.step)\n",
    "\n",
    "        return\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        print('calling configure_optimizers')\n",
    "        lr = 0.0002  \n",
    "        b1 = 0.5\n",
    "        b2 = 0.999\n",
    "        optimizer = torch.optim.Adam(self.model.parameters(), lr=lr, betas=(b1, b2))\n",
    "        # I have no evidence to suggest scheduler is an improvement, but let's give it a whirl anyway :)\n",
    "        scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.9)\n",
    "        return [optimizer], [scheduler]\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_location = {'cuda:0':'cuda:1'}\n",
    "model = DDPM.load_from_checkpoint(checkpoint_path='/home/mark/dev/diffusion/lightning_logs/version_10/checkpoints/epoch=3-step=72936.ckpt',\n",
    "                                  map_location=map_location) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = pl.Trainer(accelerator='gpu', devices=1, max_epochs=1) \n",
    "\n",
    "trainer.fit(model=model, train_dataloaders=train_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "checkpoint_callback = pl.callbacks.ModelCheckpoint(\n",
    "    save_top_k=10,\n",
    "    every_n_epochs=1,\n",
    "    monitor = 'loss',\n",
    "    mode = 'min'\n",
    ")\n",
    "\n",
    "map_location = {'cuda:0':'cuda:1'}\n",
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "logger = TensorBoardLogger(save_dir=os.getcwd(), name=\"lightning_logs\", default_hp_metric=False)\n",
    "trainer = pl.Trainer(accelerator='gpu', devices=1, max_epochs=500,\n",
    "                     logger=logger, log_every_n_steps=1000, callbacks=[checkpoint_callback],\n",
    "                     checkpoint_path='/home/mark/dev/diffusion/lightning_logs/version_10/checkpoints/epoch=3-step=72936.ckpt') \n",
    "\n",
    "trainer.fit(model=model, train_dataloaders=train_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "avm-dvm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
