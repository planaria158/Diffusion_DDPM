
1. Train with no dropout included (./lightning_logs/version_25, 250 epochs)

2. Train with dropout added just to Attention block.  (./lightning_logs/version_26, 250 epochs)

3. Now add dropout to the residual block and run experiment again. (./lightning_logs/version_27)
   (results are pure crap)  2/18/24  Note this was Dropout2D (drops out entire channels, not just pixels)

4. Re-run #2 with larger image size: [96,96],  2/18/24  (./version_28)
    maybe need more channels??

5. Repeat #4 but increase channel count to : [64, 128, 256, 512, 1024]  (./lightning_logs/version_29)
    looks much better.

6. Make a movie of the image prediction trajectory...

7. Train 128x128 image size, use accumulate_grad_batches=10 in the Trainer to compensate for smaller batch sizes.
   (./lightning_logs/version_30) : converges faster than 128x128 and 64x64.  Ran for 100 epochs and results look good.

8. Train 256x256 image size (./lightning_logs/version_32, restarted and continued in /version_33)
   Ran for ~140 epochs. Final training loss = 0.072
   Result: meh!  Faces rendered quite good, few if any deformities, but background colors incorrect, and resolution is grainy.

9. 3/2/2024: Retry 256x256 with different settings.  Basically, more channels & one-fewer layer
   channels : [64, 128, 256, 512, 1024]
   down_attn: [False, False, False, True]  # for img_size : [256,256], attn at 32x32
   down_channel_indices: [[0,0], [0,1], [1,2], [2,3]] # in, out indices into channels[] for each down layer
   mid_attn:  [False, True, False] # for img_size : [256,256], attn at 16x6
   mid_channel_indices: [[3,4], [4,4], [4,3]] # in, out indices into channels[] for each mid layer
   up_attn:   [True, False, False] # for img_size : [256,256], attn at 32x32
   up_channel_indices: [[3,2], [2,1], [1,0]] # in, out indices into channels[] for each up layer

   batch size is now 6 and accumulate_grad_batches=32
   Also, I added back in Dropout to Residual Blocks (but pixel dropout, not dropout2d)
   Also, added mlflow.pytorch.autolog() to train.py

   Stopped after 12 epochs.  Way TOO SLOW

10. Rerun #7 above to re-establish results.
    batch_size: 16
    accumulate_grad_batches: 16



- 128x128 with only 32x32 attention (or only 16x16 attention)
  

- Try cosine schedule (Improved Denoising Diffusion Probabilistic Models)

- Try a UNet++ version of the model.

- Assuming good quality results, create 50K generated images and calculate FID score.

- Try DDIM image generation (DENOISING DIFFUSION IMPLICIT MODELS): http://arxiv.org/abs/2010.02502

- Look at loss per time step from fully trained model.

- Try mixed precision training again....


Long-term:
1. Implement DiT : diffusion transformer architecture (used in Sora, for example)
   http://arxiv.org/abs/2212.09748



